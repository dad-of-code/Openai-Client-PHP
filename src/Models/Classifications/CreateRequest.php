<?php

/**
 * Copyright (c) 2022 Tectalic (https://tectalic.com)
 *
 * For copyright and license information, please view the LICENSE file that was distributed with this source code.
 *
 * Please see the README.md file for usage instructions.
 */

declare(strict_types=1);

namespace Tectalic\OpenAi\Models\Classifications;

use Tectalic\OpenAi\Models\AbstractModel;

final class CreateRequest extends AbstractModel
{
    /**
     * List of required property names.
     *
     * These properties must all be set when this Model is instantiated.
     */
    protected const REQUIRED = ['model', 'query'];

    /** @var bool */
    protected $ignoreMissing = false;

    /**
     * ID of the model to use. You can use the List models API to see all of your
     * available models, or see our Model overview for descriptions of them.
     *
     * @var string
     */
    public $model;

    /**
     * Query to be classified.
     *
     * Example: 'The plot is not very attractive.'
     *
     * @var string
     */
    public $query;

    /**
     * A list of examples with labels, in the following format:
     * [["The movie is so interesting.", "Positive"], ["It is quite boring.",
     * "Negative"], ...]
     * All the label strings will be normalized to be capitalized.
     * You should specify either examples or file, but not both.
     *
     * @var array
     */
    public $examples;

    /**
     * The ID of the uploaded file that contains training examples. See upload file for
     * how to upload a file of the desired format and purpose.
     * You should specify either examples or file, but not both.
     *
     * @var string|null
     */
    public $file;

    /**
     * The set of categories being classified. If not specified, candidate labels will
     * be automatically collected from the examples you provide. All the label strings
     * will be normalized to be capitalized.
     *
     * Default Value: null
     *
     * @var string[]|null
     */
    public $labels;

    /**
     * ID of the model to use for Search. You can select one of ada, babbage, curie, or
     * davinci.
     *
     * Default Value: 'ada'
     *
     * @var string|null
     */
    public $search_model;

    /**
     * What sampling temperature to use. Higher values mean the model will take more
     * risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones
     * with a well-defined answer.
     *
     * Example: 0
     *
     * Default Value: 0
     *
     * @var float|int|null
     */
    public $temperature;

    /**
     * Include the log probabilities on the logprobs most likely tokens, as well the
     * chosen tokens. For example, if logprobs is 5, the API will return a list of the
     * 5 most likely tokens. The API will always return the logprob of the sampled
     * token, so there may be up to logprobs+1 elements in the response.
     * The maximum value for logprobs is 5. If you need more than this, please contact
     * support@openai.com and describe your use case.
     * When logprobs is set, completion will be automatically added into expand to get
     * the logprobs.
     *
     * Default Value: null
     *
     * @var int|null
     */
    public $logprobs;

    /**
     * The maximum number of examples to be ranked by Search when using file. Setting
     * it to a higher value leads to improved accuracy but with increased latency and
     * cost.
     *
     * Default Value: 200
     *
     * @var int|null
     */
    public $max_examples;

    /**
     * Modify the likelihood of specified tokens appearing in the completion.
     * Accepts a json object that maps tokens (specified by their token ID in the GPT
     * tokenizer) to an associated bias value from -100 to 100. You can use this
     * tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to token
     * IDs. Mathematically, the bias is added to the logits generated by the model
     * prior to sampling. The exact effect will vary per model, but values between -1
     * and 1 should decrease or increase likelihood of selection; values like -100 or
     * 100 should result in a ban or exclusive selection of the relevant token.
     * As an example, you can pass {"50256": -100} to prevent the <|endoftext|> token
     * from being generated.
     *
     * Default Value: null
     *
     * @var \Tectalic\OpenAi\Models\Classifications\CreateRequestLogitBias|null
     */
    public $logit_bias;

    /**
     * If set to true, the returned JSON will include a "prompt" field containing the
     * final prompt that was used to request a completion. This is mainly useful for
     * debugging purposes.
     *
     * Default Value: false
     *
     * @var bool|null
     */
    public $return_prompt;

    /**
     * A special boolean flag for showing metadata. If set to true, each document entry
     * in the returned JSON will contain a "metadata" field.
     * This flag only takes effect when file is set.
     *
     * Default Value: false
     *
     * @var bool|null
     */
    public $return_metadata;

    /**
     * If an object name is in the list, we provide the full information of the object;
     * otherwise, we only provide the object ID. Currently we support completion and
     * file objects for expansion.
     *
     * Default Value: []
     *
     * @var mixed
     */
    public $expand;

    /**
     * A unique identifier representing your end-user, which will help OpenAI to
     * monitor and detect abuse.
     *
     * Example: 'user-1234'
     *
     * @var string
     */
    public $user;
}
